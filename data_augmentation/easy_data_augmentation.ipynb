{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ksenticnet_kaist import ksenticnet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ksenticnet에서 유의어만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dic = dict()\n",
    "\n",
    "for key, value in ksenticnet.items():\n",
    "    temp_value = []\n",
    "    for v in value:\n",
    "        if v.isalpha() and not v.isupper() and not v.islower():\n",
    "            temp_value.append(v)\n",
    "\n",
    "    if temp_value:\n",
    "        word_dic[key] = temp_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. kwn (Korean WordNet)과의 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"../data/wordnet.pickle\", \"rb\") as f:\n",
    "    kwn = pickle.load(f)\n",
    "\n",
    "for key, value in kwn.items():\n",
    "\n",
    "    if word_dic.get(key): # key가 있다면\n",
    "        value_1 = set(word_dic[key])\n",
    "        value_2 = set(kwn[key])\n",
    "        word_dic[key] = list(value_1 | value_2)\n",
    "\n",
    "    elif len(value) > 1:\n",
    "        word_dic[key] = value    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kss\n",
    "import random\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_replacement(text, num_replacement):\n",
    "\n",
    "    morphemes = kss.split_morphemes(text, drop_space=False)\n",
    "    morphemes_copy = list(enumerate(morphemes.copy()))\n",
    "\n",
    "    cnt_replacement = 0\n",
    "\n",
    "    # 순서 섞기\n",
    "    random.shuffle(morphemes_copy)\n",
    "\n",
    "    for idx, (morph, pos) in morphemes_copy:\n",
    "\n",
    "        if pos.startswith(\"N\") or pos.startswith(\"V\"):\n",
    "            dict_value = word_dic.get(morph)\n",
    "\n",
    "            if dict_value:\n",
    "                replace_word = set(dict_value).pop()\n",
    "                morphemes[idx] = (replace_word, pos)\n",
    "                cnt_replacement += 1\n",
    "            \n",
    "        if cnt_replacement > num_replacement:\n",
    "            break\n",
    "\n",
    "    # 문서 재배치\n",
    "    text = \"\"\n",
    "\n",
    "    for morph, _ in morphemes:\n",
    "        text += morph\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_insertion(text, num_replacement):\n",
    "    \n",
    "    morphemes = kss.split_morphemes(text, drop_space=False)\n",
    "    morphemes_copy = list(enumerate(morphemes.copy()))\n",
    "\n",
    "    cnt_replacement = 0\n",
    "    inserted = []\n",
    "\n",
    "    # 순서 섞기\n",
    "    random.shuffle(morphemes_copy)\n",
    "\n",
    "    for idx, (morph, pos) in morphemes_copy:\n",
    "\n",
    "        if pos.startswith(\"N\") or pos.startswith(\"V\"):\n",
    "            dict_value = word_dic.get(morph)\n",
    "\n",
    "            if dict_value:\n",
    "                replace_word = set(dict_value).pop()\n",
    "                rand_int = random.randint(0, len(morphemes_copy)) + random.random()\n",
    "                inserted.append((rand_int, (replace_word, pos)))\n",
    "                cnt_replacement += 1\n",
    "            \n",
    "        if cnt_replacement > num_replacement:\n",
    "            break\n",
    "\n",
    "    # 문서 재배치\n",
    "    text = \"\"\n",
    "    morphemes_copy.extend(inserted)\n",
    "    morphemes_copy.sort()\n",
    "\n",
    "    for _, (morph, _) in morphemes_copy:\n",
    "        text += morph\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/stopword.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    stopwords = set([line.strip() for line in f.readlines()])\n",
    "\n",
    "def random_deletetion(text, num_del):\n",
    "    morphemes = kss.split_morphemes(text, drop_space=False)\n",
    "    morphemes_copy = set(enumerate(morphemes.copy()))\n",
    "\n",
    "    # random delete\n",
    "    del_cnt = 0\n",
    "    num_iter = 0\n",
    "\n",
    "    while del_cnt < num_del and num_iter < len(text):\n",
    "        popped = morphemes_copy.pop()\n",
    "        _, (morph, pos) = popped\n",
    "\n",
    "        if morph in stopwords or not morph.isalpha():\n",
    "            morphemes_copy.add(popped)\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            del_cnt += 1\n",
    "\n",
    "        num_iter += 1\n",
    "\n",
    "    morphemes_copy = sorted(list(morphemes_copy))\n",
    "    \n",
    "    text = \"\"\n",
    "\n",
    "    for _, (morph, _) in morphemes_copy:\n",
    "        text += morph\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EDA(text):\n",
    "    num_process = int(len(text.split())*0.1) + 1\n",
    "    text_1 = synonym_replacement(text, num_process)\n",
    "    text_2 = random_insertion(text, num_process)\n",
    "    text_3 = random_deletetion(text, num_process)\n",
    "\n",
    "    return [text_1, text_2, text_3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 데이터 증강하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 가져오기\n",
    "\n",
    "data_path = r\"../data/annotated_data_final.xlsx\"\n",
    "df = pd.read_excel(data_path, index_col=None)[['text', 'label']]\n",
    "\n",
    "# augmentated 여부 붙이기\n",
    "df['augmented'] = np.zeros([len(df)], dtype=np.int64)\n",
    "\n",
    "# label별 분류\n",
    "df_label_0 = df[df.label == 0] # 혐의 없음\n",
    "df_label_1 = df[df.label == 1] # 기관 사칭형\n",
    "df_label_2 = df[df.label == 2] # 대출 빙자형\n",
    "df_label_3 = df[df.label == 3] # 기타"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 214/214 [00:00<00:00, 3965.84it/s]\n",
      "100%|██████████| 97/97 [00:00<00:00, 5695.19it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22.71it/s]\n"
     ]
    }
   ],
   "source": [
    "dfs = [(2, df_label_2), (3, df_label_3)] # 1이 제일 많으므로 1을 제일 마지막으로 수행\n",
    "failed = []\n",
    "\n",
    "for label, df in tqdm.tqdm(dfs):\n",
    "    temp = []\n",
    "\n",
    "    # 안정성을 위해 비효율적이더라도 나눠서 실행\n",
    "    for original_text in tqdm.tqdm(df.text.values): # ko -> eng -> ko\n",
    "\n",
    "        try:\n",
    "            texts = EDA(original_text)\n",
    "            temp.extend([(text, label, 1) for text in texts])\n",
    "        except:\n",
    "            failed.append(original_text)\n",
    "            continue\n",
    "    \n",
    "    temp_df = pd.DataFrame(temp, columns =['text', 'label', 'augmented'])\n",
    "    temp_df.to_csv(fr\"../data/{label}_eda3.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
